<template>
  <view class="voice-call-container">
    <!-- è¿”å›æŒ‰é’® -->
    <view class="back-button" @click="handleBack">
      <text class="back-icon">â†</text>
      <text class="back-text">è¿”å›</text>
    </view>

    <!-- è¿æ¥çŠ¶æ€æŒ‡ç¤ºå™¨ -->
    <view class="connection-status">
      <view class="status-indicator">
        <view :class="['status-dot', isConnected ? 'status-connected' : 'status-disconnected']"></view>
        <text>{{ isConnected ? "å·²è¿æ¥" : "ç¦»çº¿" }}</text>
      </view>
    </view>

    <!-- èŠå¤©æ¶ˆæ¯æµ -->
    <scroll-view 
      class="chat-container" 
      scroll-y 
      :scroll-into-view="scrollIntoViewId"
      scroll-with-animation
      @scroll="onScroll"
      :lower-threshold="100"
    >
      <view id="scroll-top-pad"></view>
      <view class="chat-stream">
        <ChatMessage 
          v-for="(msg, index) in messages" 
          :key="index" 
          :id="'msg-' + index"
          :message="msg" 
          :disabled="isTyping" 
        />
      </view>
      <view style="height: 20px" id="bottom-anchor"></view>
    </scroll-view>

    <!-- è¾“å…¥æ¡† -->
    <view class="input-bar">
      <input
        id="quickInput"
        v-model="inputMessage"
        class="control-input"
        type="text"
        placeholder="è¾“å…¥æ¶ˆæ¯ï¼ŒæŒ‰Enterå‘é€"
        confirm-type="send"
      />
      <button class="send-btn-inline" @click="handleSendMessage">
        <text class="send-icon-inline">â†‘</text>
      </button>
    </view>

    <!-- åº•éƒ¨æ§åˆ¶æ  -->
    <view class="control-bar">
      <button class="control-btn" :class="{ recording: isRecording }" :disabled="!canRecord" @click="handleRecord">
        <text class="btn-icon">ğŸ¤</text>
        <text class="btn-text">{{ isRecording ? "å½•éŸ³ä¸­" : "å½•éŸ³" }}</text>
      </button>
    </view>

    <!-- è®¾ç½®å¼¹çª— -->
    <view v-if="showSettings" class="modal" @click="handleModalClick">
      <view class="modal-content" @click.stop>
        <view class="modal-header">
          <text class="modal-title">è®¾ç½®</text>
          <button class="close-btn" @click="showSettings = false">Ã—</button>
        </view>
        <view class="modal-body">
          <view class="input-group">
            <text class="label">OTAæœåŠ¡å™¨åœ°å€:</text>
            <input v-model="otaUrl" class="input" placeholder="http://127.0.0.1:8002/xiaozhi/ota/" />
          </view>
          <view class="input-group">
            <text class="label">è®¾å¤‡ID:</text>
            <input v-model="deviceId" class="input" placeholder="web_test_client" />
          </view>
          <view class="input-group">
            <text class="label">å®¢æˆ·ç«¯ID:</text>
            <input v-model="clientId" class="input" placeholder="web_test_client" />
          </view>
          <view class="input-group">
            <text class="label">è®¾å¤‡MAC:</text>
            <input v-model="deviceMac" class="input" placeholder="web_test_device" />
          </view>
          <view class="input-group">
            <text class="label">è®¾å¤‡åç§°:</text>
            <input v-model="deviceName" class="input" placeholder="Webæµ‹è¯•è®¾å¤‡" />
          </view>
        </view>
      </view>
    </view>
  </view>
</template>

<script setup>
import { ref, computed, onUnmounted, onMounted, nextTick } from "vue";
import ChatMessage from "@/pages/student/ai-assistant/components/chatMessage.vue";

// çŠ¶æ€ç®¡ç†
const isConnected = ref(false);
const isRecording = ref(false);
const showSettings = ref(false);
const messages = ref([]);
const scrollIntoViewId = ref("");
const inputMessage = ref("");
const isTyping = ref(false);

// æ»šåŠ¨æ§åˆ¶
const shouldAutoScroll = ref(true);
const isProgrammaticScroll = ref(false);

// é…ç½®
const otaUrl = ref("http://192.168.5.254:8002/xiaozhi/ota/");
const deviceMac = ref("web_test_device");
const deviceName = ref("Webæµ‹è¯•è®¾å¤‡");
const deviceId = ref("F4:E7:72:BB:B3:93");
const clientId = ref("web_test_client");

// WebSocketå’ŒéŸ³é¢‘ç›¸å…³
let websocket = null;
let audioContext = null;
let mediaStream = null;
let audioProcessor = null;
let pcmDataBuffer = new Int16Array();
let audioQueue = []; // éŸ³é¢‘æ•°æ®é˜Ÿåˆ—
let isPlayingAudio = false;
let webAudioContext = null; // Web Audio APIä¸Šä¸‹æ–‡
let nextPlayTime = 0; // ä¸‹ä¸€ä¸ªéŸ³é¢‘å—çš„æ’­æ”¾æ—¶é—´
let opusDecoder = null; // Opusè§£ç å™¨

// è®¡ç®—å±æ€§
const canRecord = computed(() => isConnected.value);

// èŠ‚æµå‡½æ•°
const throttle = (func, delay) => {
  let lastCall = 0;
  return function (...args) {
    const now = Date.now();
    if (now - lastCall >= delay) {
      lastCall = now;
      func.apply(this, args);
    }
  };
};

// æ»šåŠ¨åˆ°åº•éƒ¨
const scrollToBottom = throttle(() => {
  if (!shouldAutoScroll.value) return;

  nextTick(() => {
    isProgrammaticScroll.value = true;
    scrollIntoViewId.value = "";
    nextTick(() => {
      scrollIntoViewId.value = "bottom-anchor";
    });
  });
}, 450);

// é‡ç½®è‡ªåŠ¨æ»šåŠ¨
const resetAutoScroll = () => {
  shouldAutoScroll.value = true;
  isProgrammaticScroll.value = true;
};

// ç›‘å¬æ»šåŠ¨äº‹ä»¶
const onScroll = (e) => {
  if (isProgrammaticScroll.value) {
    isProgrammaticScroll.value = false;
    return;
  }
  if (isTyping.value) {
    shouldAutoScroll.value = false;
  }
};

// æ·»åŠ æ¶ˆæ¯
const addMessage = (content, isUser = false) => {
  if (!content.trim()) {
    return;
  }
  const message = {
    sender: isUser ? "user" : "ai",
    text: content,
    html: content,
    timestamp: Date.now(),
    quickButtons: [],
    files: [],
  };

  messages.value.push(message);

  // æ»šåŠ¨åˆ°åº•éƒ¨
  nextTick(() => {
    scrollToBottom();
  });
};

// å‘é€æ–‡æœ¬æ¶ˆæ¯
let sendingMessage = false; // é˜²æ­¢é‡å¤å‘é€
const handleSendMessage = () => {
  if (sendingMessage) {
    return;
  }
  const message = inputMessage.value.trim();
  if (!message) {
    return;
  }

  // å¦‚æœæœªè¿æ¥ï¼Œæç¤ºç”¨æˆ·
  if (!isConnected.value) {
    addMessage("è¯·å…ˆç‚¹å‡»æ‹¨å·æŒ‰é’®è¿æ¥æœåŠ¡å™¨", false);
    return;
  }

  try {
    sendingMessage = true;

    if (websocket && websocket.readyState === WebSocket.OPEN) {
      const listenMessage = {
        type: "listen",
        state: "detect",
        text: message,
      };
      websocket.send(JSON.stringify(listenMessage));
      // æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
      addMessage(message, true);
    }

    // æ¸…ç©ºè¾“å…¥æ¡†
    inputMessage.value = "";

    // å»¶è¿Ÿé‡ç½®å‘é€çŠ¶æ€
    setTimeout(() => {
      sendingMessage = false;
      console.log("å‘é€çŠ¶æ€å·²é‡ç½®");
    }, 300);
  } catch (error) {
    addMessage("å‘é€æ¶ˆæ¯å¤±è´¥", false);
    sendingMessage = false;
  }
};

// è¿æ¥æœåŠ¡å™¨
const connect = async () => {
  try {
    addMessage("æ­£åœ¨è¿æ¥æœåŠ¡å™¨...", false);

    // è·å–WebSocketåœ°å€
    const wsUrl = await getWebSocketUrl();
    if (!wsUrl) {
      throw new Error("æ— æ³•è·å–WebSocketåœ°å€");
    }

    // åˆ›å»ºWebSocketè¿æ¥
    websocket = new WebSocket(wsUrl);
    websocket.binaryType = "arraybuffer";

    websocket.onopen = async () => {
      isConnected.value = true;
      resetAutoScroll();
      addMessage("è¿æ¥æˆåŠŸï¼Œå¼€å§‹èŠå¤©å§~ğŸ˜Š", false);

      // å‘é€helloæ¶ˆæ¯
      await sendHelloMessage();
    };

    websocket.onmessage = (event) => {
      handleWebSocketMessage(event);
    };

    websocket.onclose = () => {
      isConnected.value = false;
      addMessage("å·²æ–­å¼€è¿æ¥", false);
      cleanup();
    };

    websocket.onerror = (error) => {
      addMessage("è¿æ¥é”™è¯¯", false);
    };
  } catch (error) {
    addMessage(`è¿æ¥å¤±è´¥: ${error.message}`, false);
  }
};

// è·å–WebSocketåœ°å€
const getWebSocketUrl = async () => {
  try {
    // å‘é€OTA POSTè¯·æ±‚ - ä½¿ç”¨åŸç”Ÿuni.requestå› ä¸ºéœ€è¦è‡ªå®šä¹‰å®Œæ•´URL
    const res = await new Promise((resolve, reject) => {
      uni.request({
        url: otaUrl.value,
        method: "POST",
        header: {
          "Content-Type": "application/json",
          "Device-Id": deviceId.value,
          "Client-Id": clientId.value,
        },
        data: {
          version: 0,
          uuid: "",
          application: {
            name: "xiaozhi-web-test",
            version: "1.0.0",
            compile_time: "2025-04-16 10:00:00",
            idf_version: "4.4.3",
            elf_sha256: "1234567890abcdef1234567890abcdef1234567890abcdef",
          },
          ota: { label: "xiaozhi-web-test" },
          board: {
            type: deviceName.value,
            ssid: "xiaozhi-web-test",
            rssi: 0,
            channel: 0,
            ip: "192.168.1.1",
            mac: deviceMac.value,
          },
          flash_size: 0,
          minimum_free_heap_size: 0,
          mac_address: deviceMac.value,
          chip_model_name: "",
          chip_info: { model: 0, cores: 0, revision: 0, features: 0 },
          partition_table: [{ label: "", type: 0, subtype: 0, address: 0, size: 0 }],
        },
        success: (response) => {
          resolve(response);
        },
        fail: (error) => {
          console.error("OTAè¯·æ±‚å¤±è´¥:", error);
          reject(error);
        },
      });
    });

    if (res && res.data && res.data.websocket) {
      const wsInfo = res.data.websocket;

      // æ„å»ºWebSocket URL
      let wsUrl = wsInfo.url;
      const urlObj = new URL(wsUrl);

      // æ·»åŠ tokenå‚æ•°
      if (wsInfo.token) {
        const token = wsInfo.token.startsWith("Bearer ") ? wsInfo.token : "Bearer " + wsInfo.token;
        urlObj.searchParams.append("authorization", token);
      }

      // æ·»åŠ è®¤è¯å‚æ•°
      urlObj.searchParams.append("device-id", deviceId.value);
      urlObj.searchParams.append("client-id", clientId.value);

      return urlObj.toString();
    }

    throw new Error("æ— æ³•è·å–WebSocketåœ°å€");
  } catch (error) {
    console.error("è·å–WebSocketåœ°å€å¤±è´¥:", error);
    addMessage(`OTAè¯·æ±‚å¤±è´¥: ${error.errMsg || error.message}`, false);
    return null;
  }
};

// å‘é€helloæ¶ˆæ¯
const sendHelloMessage = async () => {
  if (!websocket || websocket.readyState !== WebSocket.OPEN) return;

  const helloMessage = {
    type: "hello",
    device_id: deviceId.value,
    device_name: deviceName.value,
    device_mac: deviceMac.value,
    token: "",
    features: { mcp: true },
  };

  websocket.send(JSON.stringify(helloMessage));
};

// å¤„ç†WebSocketæ¶ˆæ¯
const handleWebSocketMessage = (event) => {
  try {
    if (typeof event.data === "string") {
      const message = JSON.parse(event.data);
      handleTextMessage(message);
    } else {
      // å¤„ç†äºŒè¿›åˆ¶éŸ³é¢‘æ•°æ®
      handleBinaryMessage(event.data);
    }
  } catch (error) {
    // å¿½ç•¥é”™è¯¯
  }
};

// å¤„ç†æ–‡æœ¬æ¶ˆæ¯
const handleTextMessage = (message) => {
  if (message.type === "tts" || message === "llm") {
    addMessage(message.text, false);
  }
};

// å¤„ç†äºŒè¿›åˆ¶æ¶ˆæ¯ï¼ˆéŸ³é¢‘æ’­æ”¾ï¼‰
const handleBinaryMessage = async (data) => {
  try {
    // å¦‚æœæ˜¯ç©ºæ•°æ®ï¼Œè¡¨ç¤ºéŸ³é¢‘æµç»“æŸ
    if (data.byteLength === 0) {
      return;
    }

    // å°†éŸ³é¢‘æ•°æ®æ·»åŠ åˆ°é˜Ÿåˆ—
    audioQueue.push(new Uint8Array(data));

    // å¦‚æœå½“å‰æ²¡æœ‰åœ¨æ’­æ”¾ï¼Œå¼€å§‹æ’­æ”¾
    if (!isPlayingAudio) {
      playAudioQueue();
    }
  } catch (error) {
    // å¿½ç•¥é”™è¯¯
  }
};

// ç­‰å¾…Opusåº“åŠ è½½
const waitForOpusLibrary = () => {
  return new Promise((resolve) => {
    const checkOpus = () => {
      // æ£€æŸ¥Moduleæ˜¯å¦å­˜åœ¨
      if (typeof window.Module === "undefined") {
        setTimeout(checkOpus, 100);
        return;
      }

      // æ£€æŸ¥Module.instanceï¼ˆlibopus.jså¯¼å‡ºæ–¹å¼ï¼‰
      if (typeof window.Module.instance !== "undefined") {
        const mod = window.Module.instance;
        if (typeof mod._opus_decoder_get_size === "function") {
          window.ModuleInstance = mod;
          resolve(true);
          return;
        }
      }

      // æ£€æŸ¥å…¨å±€Moduleå‡½æ•°
      if (typeof window.Module._opus_decoder_get_size === "function") {
        window.ModuleInstance = window.Module;
        resolve(true);
        return;
      }

      setTimeout(checkOpus, 100);
    };
    checkOpus();
  });
};

// åˆå§‹åŒ–Opusè§£ç å™¨
const initOpusDecoder = async () => {
  if (opusDecoder) return opusDecoder;

  try {
    // ç­‰å¾…Opusåº“åŠ è½½
    await waitForOpusLibrary();

    const mod = window.ModuleInstance;

    if (!mod || typeof mod._opus_decoder_get_size !== "function") {
      addMessage("Opusåº“æœªæ­£ç¡®åŠ è½½", false);
      return null;
    }

    opusDecoder = {
      channels: 1,
      rate: 16000,
      frameSize: 960,
      module: mod,
      decoderPtr: null,

      init: function () {
        if (this.decoderPtr) return true;

        try {
          const decoderSize = this.module._opus_decoder_get_size(this.channels);
          this.decoderPtr = this.module._malloc(decoderSize);

          if (!this.decoderPtr) {
            return false;
          }

          const err = this.module._opus_decoder_init(this.decoderPtr, this.rate, this.channels);

          if (err < 0) {
            this.destroy();
            return false;
          }

          return true;
        } catch (error) {
          return false;
        }
      },

      decode: function (opusData) {
        if (!this.decoderPtr) {
          if (!this.init()) {
            return new Int16Array(0);
          }
        }

        try {
          const mod = this.module;
          const opusPtr = mod._malloc(opusData.length);
          mod.HEAPU8.set(opusData, opusPtr);

          const pcmPtr = mod._malloc(this.frameSize * 2);

          const decodedSamples = mod._opus_decode(this.decoderPtr, opusPtr, opusData.length, pcmPtr, this.frameSize, 0);

          if (decodedSamples < 0) {
            mod._free(opusPtr);
            mod._free(pcmPtr);
            return new Int16Array(0);
          }

          const decodedData = new Int16Array(decodedSamples);
          for (let i = 0; i < decodedSamples; i++) {
            decodedData[i] = mod.HEAP16[(pcmPtr >> 1) + i];
          }

          mod._free(opusPtr);
          mod._free(pcmPtr);

          return decodedData;
        } catch (error) {
          return new Int16Array(0);
        }
      },

      destroy: function () {
        if (this.decoderPtr) {
          this.module._free(this.decoderPtr);
          this.decoderPtr = null;
        }
      },
    };

    if (!opusDecoder.init()) {
      opusDecoder = null;
      return null;
    }

    return opusDecoder;
  } catch (error) {
    return null;
  }
};

// åˆå§‹åŒ–Web Audio Context
const initWebAudioContext = () => {
  if (!webAudioContext) {
    // @ts-ignore - webkitAudioContext for Safari compatibility
    const AudioContextClass = window.AudioContext || window.webkitAudioContext;
    webAudioContext = new AudioContextClass({
      sampleRate: 16000,
    });
    nextPlayTime = webAudioContext.currentTime;
  }
  return webAudioContext;
};

// å°†PCMæ•°æ®è½¬æ¢ä¸ºAudioBuffer
const pcmToAudioBuffer = (pcmData, sampleRate = 16000) => {
  const audioBuffer = webAudioContext.createBuffer(1, pcmData.length, sampleRate);
  const channelData = audioBuffer.getChannelData(0);

  // å°†Int16è½¬æ¢ä¸ºFloat32 (-1.0 åˆ° 1.0)
  for (let i = 0; i < pcmData.length; i++) {
    channelData[i] = pcmData[i] / 32768.0;
  }

  return audioBuffer;
};

// æ’­æ”¾éŸ³é¢‘é˜Ÿåˆ—
const playAudioQueue = async () => {
  if (isPlayingAudio || audioQueue.length === 0) return;

  isPlayingAudio = true;

  try {
    // åˆå§‹åŒ–Web Audio Context
    const ctx = initWebAudioContext();

    // æ¢å¤éŸ³é¢‘ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœè¢«æš‚åœï¼‰
    if (ctx.state === "suspended") {
      await ctx.resume();
    }

    // åˆå§‹åŒ–Opusè§£ç å™¨ï¼ˆå¼‚æ­¥ï¼‰
    if (!opusDecoder) {
      opusDecoder = await initOpusDecoder();
      if (!opusDecoder) {
        isPlayingAudio = false;
        return;
      }
    }

    // å¤„ç†é˜Ÿåˆ—ä¸­çš„æ‰€æœ‰éŸ³é¢‘æ•°æ®
    while (audioQueue.length > 0) {
      const opusData = audioQueue.shift();

      try {
        // ä½¿ç”¨Opusè§£ç å™¨è§£ç æ•°æ®
        const pcmData = opusDecoder.decode(opusData);

        if (pcmData.length === 0) {
          continue;
        }

        // åˆ›å»ºAudioBuffer
        const audioBuffer = pcmToAudioBuffer(pcmData);

        // åˆ›å»ºéŸ³é¢‘æº
        const source = ctx.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(ctx.destination);

        // è®¡ç®—æ’­æ”¾æ—¶é—´
        const currentTime = ctx.currentTime;
        const playTime = Math.max(currentTime, nextPlayTime);

        // å¼€å§‹æ’­æ”¾
        source.start(playTime);

        // æ›´æ–°ä¸‹ä¸€ä¸ªæ’­æ”¾æ—¶é—´
        nextPlayTime = playTime + audioBuffer.duration;
      } catch (error) {
        // æ’­æ”¾å¤±è´¥ï¼Œè·³è¿‡è¿™ä¸ªç‰‡æ®µ
      }
    }

    // ç­‰å¾…æ‰€æœ‰éŸ³é¢‘æ’­æ”¾å®Œæˆ
    const waitTime = Math.max(0, (nextPlayTime - ctx.currentTime) * 1000);
    setTimeout(() => {
      isPlayingAudio = false;

      // å¦‚æœæœ‰æ–°çš„éŸ³é¢‘æ•°æ®ï¼Œç»§ç»­æ’­æ”¾
      if (audioQueue.length > 0) {
        playAudioQueue();
      }
    }, waitTime);
  } catch (error) {
    isPlayingAudio = false;
  }
};

// æ–­å¼€è¿æ¥
const disconnect = () => {
  if (websocket) {
    websocket.close();
    websocket = null;
  }
  cleanup();
};

// å½•éŸ³æ§åˆ¶
const handleRecord = async () => {
  if (isRecording.value) {
    stopRecording();
  } else {
    await startRecording();
  }
};

// å¼€å§‹å½•éŸ³
const startRecording = async () => {
  try {
    // è·å–éº¦å…‹é£æƒé™
    mediaStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        echoCancellation: true,
        noiseSuppression: true,
        sampleRate: 16000,
        channelCount: 1,
      },
    });

    // åˆ›å»ºéŸ³é¢‘ä¸Šä¸‹æ–‡
    // @ts-ignore - webkitAudioContext for Safari compatibility
    const AudioContextClass = window.AudioContext || window.webkitAudioContext;
    audioContext = new AudioContextClass({ sampleRate: 16000 });

    if (audioContext.state === "suspended") {
      await audioContext.resume();
    }

    // åˆ›å»ºéŸ³é¢‘å¤„ç†å™¨
    const source = audioContext.createMediaStreamSource(mediaStream);

    // ä½¿ç”¨ScriptProcessorå¤„ç†éŸ³é¢‘
    audioProcessor = audioContext.createScriptProcessor(4096, 1, 1);

    audioProcessor.onaudioprocess = (event) => {
      if (!isRecording.value) return;

      const input = event.inputBuffer.getChannelData(0);
      const buffer = new Int16Array(input.length);

      for (let i = 0; i < input.length; i++) {
        buffer[i] = Math.max(-32768, Math.min(32767, Math.floor(input[i] * 32767)));
      }

      processPCMBuffer(buffer);
    };

    source.connect(audioProcessor);
    audioProcessor.connect(audioContext.destination);

    // è®¾ç½®å½•éŸ³çŠ¶æ€ä¸ºtrue
    isRecording.value = true;
    pcmDataBuffer = new Int16Array();
  } catch (error) {
    // å‡ºé”™æ—¶ç¡®ä¿çŠ¶æ€ä¸ºfalse
    isRecording.value = false;

    // æ¸…ç†å¯èƒ½å·²åˆ›å»ºçš„èµ„æº
    if (audioProcessor) {
      try {
        audioProcessor.disconnect();
      } catch (e) {}
      audioProcessor = null;
    }

    if (mediaStream) {
      try {
        mediaStream.getTracks().forEach((track) => track.stop());
      } catch (e) {}
      mediaStream = null;
    }

    if (audioContext) {
      try {
        audioContext.close();
      } catch (e) {}
      audioContext = null;
    }

    addMessage("å½•éŸ³å¯åŠ¨å¤±è´¥ï¼Œè¯·æ£€æŸ¥éº¦å…‹é£æƒé™", false);
  }
};

// å¤„ç†PCMç¼“å†²
const processPCMBuffer = (buffer) => {
  if (!isRecording.value) return;

  // åˆå¹¶ç¼“å†²åŒº
  const newBuffer = new Int16Array(pcmDataBuffer.length + buffer.length);
  newBuffer.set(pcmDataBuffer);
  newBuffer.set(buffer, pcmDataBuffer.length);
  pcmDataBuffer = newBuffer;

  // æ¯960ä¸ªé‡‡æ ·ç‚¹å‘é€ä¸€æ¬¡
  const samplesPerFrame = 960;
  while (pcmDataBuffer.length >= samplesPerFrame) {
    const frameData = pcmDataBuffer.slice(0, samplesPerFrame);
    pcmDataBuffer = pcmDataBuffer.slice(samplesPerFrame);

    // ç›´æ¥å‘é€PCMæ•°æ®ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…åº”è¯¥ç¼–ç ä¸ºOpusï¼‰
    if (websocket && websocket.readyState === WebSocket.OPEN) {
      websocket.send(frameData.buffer);
    }
  }
};

// åœæ­¢å½•éŸ³
const stopRecording = () => {
  // ç«‹å³è®¾ç½®å½•éŸ³çŠ¶æ€ä¸ºfalse
  isRecording.value = false;

  // æ–­å¼€éŸ³é¢‘å¤„ç†å™¨
  if (audioProcessor) {
    try {
      audioProcessor.disconnect();
    } catch (e) {
      // å¿½ç•¥æ–­å¼€è¿æ¥é”™è¯¯
    }
    audioProcessor = null;
  }

  // åœæ­¢åª’ä½“æµ
  if (mediaStream) {
    try {
      mediaStream.getTracks().forEach((track) => track.stop());
    } catch (e) {
      // å¿½ç•¥åœæ­¢è½¨é“é”™è¯¯
    }
    mediaStream = null;
  }

  // å…³é—­éŸ³é¢‘ä¸Šä¸‹æ–‡
  if (audioContext) {
    try {
      audioContext.close();
    } catch (e) {
      // å¿½ç•¥å…³é—­é”™è¯¯
    }
    audioContext = null;
  }

  // å‘é€ç»“æŸä¿¡å·
  if (websocket && websocket.readyState === WebSocket.OPEN) {
    try {
      const emptyFrame = new Uint8Array(0);
      websocket.send(emptyFrame);
    } catch (e) {
      // å¿½ç•¥å‘é€é”™è¯¯
    }
  }

  // æ¸…ç©ºPCMç¼“å†²åŒº
  pcmDataBuffer = new Int16Array();
};

// æ¸…ç†èµ„æº
const cleanup = () => {
  if (isRecording.value) {
    stopRecording();
  }

  // audioContext å·²ç»åœ¨ stopRecording ä¸­å…³é—­ï¼Œè¿™é‡Œä¸éœ€è¦å†å…³é—­

  if (webAudioContext) {
    try {
      webAudioContext.close();
    } catch (e) {
      // å¿½ç•¥å…³é—­é”™è¯¯
    }
    webAudioContext = null;
  }

  if (opusDecoder) {
    try {
      opusDecoder.destroy();
    } catch (e) {
      // å¿½ç•¥é”€æ¯é”™è¯¯
    }
    opusDecoder = null;
  }

  audioQueue = [];
  isPlayingAudio = false;
  nextPlayTime = 0;
};

// æ¨¡æ€æ¡†ç‚¹å‡»å¤„ç†
const handleModalClick = () => {
  showSettings.value = false;
};

// è¿”å›æŒ‰é’®å¤„ç†
const handleBack = () => {
  // å¦‚æœæ­£åœ¨è¿æ¥æˆ–å½•éŸ³ï¼Œå…ˆæ–­å¼€
  if (isConnected.value || isRecording.value) {
    disconnect();
  }

  // è¿”å›ä¸Šä¸€é¡µ
  uni.navigateBack({
    delta: 1,
  });
};

// ç»„ä»¶æŒ‚è½½æ—¶è‡ªåŠ¨è¿æ¥
onMounted(async () => {
  // è‡ªåŠ¨è¿æ¥æœåŠ¡å™¨
  if (otaUrl.value.trim()) {
    await connect();
  } else {
    addMessage("è¯·åœ¨è®¾ç½®ä¸­é…ç½®OTAæœåŠ¡å™¨åœ°å€", false);
  }
  
  // åˆå§‹åŒ–æ»šåŠ¨
  resetAutoScroll();
  nextTick(() => {
    scrollToBottom();
  });
});

// ç»„ä»¶å¸è½½æ—¶æ¸…ç†
onUnmounted(() => {
  disconnect();
  cleanup();
});
</script>

<style lang="scss" scoped src="./style.scss"></style>
